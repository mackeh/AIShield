id: AISHIELD-PY-LLM-001
title: Unsanitized User Input in LLM Prompt
severity: critical
confidence_that_ai_generated: 0.88
languages: [python]
category: llm
cwe_id: CWE-77
owasp_category: A03:2021 - Injection
ai_tendency: AI examples often concatenate user input directly into prompts without sanitization.
pattern:
  all:
    - "f\""
    - "{user"
  any:
    - "openai"
    - "anthropic"
    - "completion"
fix:
  suggestion: Use structured prompt templates with input validation and sanitization. Separate user input from system instructions using the messages API role boundaries.
tags: [llm, prompt-injection]
